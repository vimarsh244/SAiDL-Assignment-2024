{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "You appear to be missing MuJoCo.  We expected to find the file here: C:\\Users\\Vimarsh\\.mujoco\\mujoco210\n",
      "\n",
      "This package only provides python bindings, the library must be installed separately.\n",
      "\n",
      "Please follow the instructions on the README to install MuJoCo\n",
      "\n",
      "    https://github.com/openai/mujoco-py#install-mujoco\n",
      "\n",
      "Which can be downloaded from the website\n",
      "\n",
      "    https://www.roboti.us/index.html\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "\nYou appear to be missing MuJoCo.  We expected to find the file here: C:\\Users\\Vimarsh\\.mujoco\\mujoco210\n\nThis package only provides python bindings, the library must be installed separately.\n\nPlease follow the instructions on the README to install MuJoCo\n\n    https://github.com/openai/mujoco-py#install-mujoco\n\nWhich can be downloaded from the website\n\n    https://www.roboti.us/index.html\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 170\u001b[0m\n\u001b[0;32m    167\u001b[0m     env\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 170\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHopper-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    173\u001b[0m     episodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gym\\envs\\registration.py:581\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[0;32m    578\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m spec_\u001b[38;5;241m.\u001b[39mentry_point\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;66;03m# Assume it's a string\u001b[39;00m\n\u001b[1;32m--> 581\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_point\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m mode \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrender_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    584\u001b[0m apply_human_rendering \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gym\\envs\\registration.py:61\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads an environment with name and returns an environment creation function\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    Calls the environment constructor\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m mod_name, attr_name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, attr_name)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:783\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gym\\envs\\mujoco\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MujocoEnv, MuJocoPyEnv  \u001b[38;5;66;03m# isort:skip\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AntEnv\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhalf_cheetah\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HalfCheetahEnv\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gym\\envs\\mujoco\\mujoco_env.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspaces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Space\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmujoco_py\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     13\u001b[0m     MUJOCO_PY_IMPORT_ERROR \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mujoco_py\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmujoco_py\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cymj, ignore_mujoco_warnings, functions, MujocoException\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmujoco_py\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerated\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m const\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmujoco_py\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmjrenderpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MjRenderPool\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mujoco_py\\builder.py:503\u001b[0m\n\u001b[0;32m    499\u001b[0m     build_fn_cleanup(name)\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39m__fun\n\u001b[1;32m--> 503\u001b[0m mujoco_path \u001b[38;5;241m=\u001b[39m \u001b[43mdiscover_mujoco\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m cymj \u001b[38;5;241m=\u001b[39m load_cython_ext(mujoco_path)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# Trick to expose all mj* functions from mujoco in mujoco_py.*\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mujoco_py\\utils.py:78\u001b[0m, in \u001b[0;36mdiscover_mujoco\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m     message \u001b[38;5;241m=\u001b[39m MISSING_MUJOCO_MESSAGE\u001b[38;5;241m.\u001b[39mformat(mujoco_path)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(message, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(message)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mujoco_path\n",
      "\u001b[1;31mException\u001b[0m: \nYou appear to be missing MuJoCo.  We expected to find the file here: C:\\Users\\Vimarsh\\.mujoco\\mujoco210\n\nThis package only provides python bindings, the library must be installed separately.\n\nPlease follow the instructions on the README to install MuJoCo\n\n    https://github.com/openai/mujoco-py#install-mujoco\n\nWhich can be downloaded from the website\n\n    https://www.roboti.us/index.html\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# Intrinsic Curiosity Module (ICM)\n",
    "class StateEncoder(nn.Module):\n",
    "    def __init__(self, state_dim, encoding_dim):\n",
    "        super(StateEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(state_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, encoding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        return self.encoder(state)\n",
    "\n",
    "class InverseModel(nn.Module):\n",
    "    def __init__(self, encoding_dim, action_dim):\n",
    "        super(InverseModel, self).__init__()\n",
    "        self.inverse_model = nn.Sequential(\n",
    "            nn.Linear(encoding_dim * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, action_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, state_encoding, next_state_encoding):\n",
    "        input_tensor = torch.cat([state_encoding, next_state_encoding], dim=1)\n",
    "        return self.inverse_model(input_tensor)\n",
    "\n",
    "class ForwardModel(nn.Module):\n",
    "    def __init__(self, encoding_dim, action_dim, stack_size=4):\n",
    "        super(ForwardModel, self).__init__()\n",
    "        self.stack_size = stack_size\n",
    "        self.forward_model = nn.Sequential(\n",
    "            nn.Linear(encoding_dim * stack_size + action_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, encoding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, state_encoding_stack, action):\n",
    "        input_tensor = torch.cat([state_encoding_stack.view(-1, self.stack_size * state_encoding_stack.shape[-1]), action], dim=1)\n",
    "        return self.forward_model(input_tensor)\n",
    "\n",
    "class ICM(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, encoding_dim, stack_size=4):\n",
    "        super(ICM, self).__init__()\n",
    "        self.state_encoder = StateEncoder(state_dim, encoding_dim)\n",
    "        self.inverse_model = InverseModel(encoding_dim, action_dim)\n",
    "        self.forward_model = ForwardModel(encoding_dim, action_dim, stack_size)\n",
    "\n",
    "    def forward(self, state, next_state, action):\n",
    "        state_encoding = self.state_encoder(state)\n",
    "        next_state_encoding = self.state_encoder(next_state)\n",
    "\n",
    "        inverse_loss = nn.MSELoss()(self.inverse_model(state_encoding, next_state_encoding), action)\n",
    "\n",
    "        state_encoding_stack = torch.cat([state_encoding.unsqueeze(1)] * self.forward_model.stack_size, dim=1)\n",
    "        forward_loss = nn.MSELoss()(self.forward_model(state_encoding_stack, action), next_state_encoding)\n",
    "\n",
    "        return inverse_loss, forward_loss\n",
    "\n",
    "# Deep Q-Network (DQN)\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Replay Buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, buffer_size):\n",
    "        self.buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "\n",
    "# Train Agent\n",
    "def train_agent(env, episodes, batch_size, buffer_size, gamma, epsilon, epsilon_decay):\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.n\n",
    "    encoding_dim = 64\n",
    "    stack_size = 4\n",
    "\n",
    "    dqn = DQN(state_dim, action_dim).to(device)\n",
    "    icm = ICM(state_dim, action_dim, encoding_dim, stack_size).to(device)\n",
    "    dqn_optimizer = optim.Adam(dqn.parameters())\n",
    "    icm_optimizer = optim.Adam(icm.parameters())\n",
    "    replay_buffer = ReplayBuffer(buffer_size)\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Choose action\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                state_tensor = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "                q_values = dqn(state_tensor)\n",
    "                action = torch.argmax(q_values).item()\n",
    "\n",
    "            # Take action and observe next state\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            # Compute intrinsic reward\n",
    "            state_tensor = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "            next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "            action_tensor = torch.tensor([action], dtype=torch.float32, device=device)\n",
    "\n",
    "            inverse_loss, forward_loss = icm(state_tensor, next_state_tensor, action_tensor)\n",
    "            intrinsic_reward = forward_loss.item()\n",
    "\n",
    "            # Add experience to replay buffer\n",
    "            replay_buffer.append(state, action, reward + intrinsic_reward, next_state, done)\n",
    "\n",
    "            # Sample from replay buffer and update networks\n",
    "            if len(replay_buffer.buffer) >= batch_size:\n",
    "                states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "\n",
    "                states_tensor = torch.tensor(states, dtype=torch.float32, device=device)\n",
    "                actions_tensor = torch.tensor(actions, dtype=torch.long, device=device).unsqueeze(1)\n",
    "                rewards_tensor = torch.tensor(rewards, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "                next_states_tensor = torch.tensor(next_states, dtype=torch.float32, device=device)\n",
    "                dones_tensor = torch.tensor(dones, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "                # Update DQN\n",
    "                q_values = dqn(states_tensor).gather(1, actions_tensor)\n",
    "                next_q_values = dqn(next_states_tensor).max(1)[0].detach()\n",
    "                expected_q_values = rewards_tensor + gamma * next_q_values * (1 - dones_tensor)\n",
    "                dqn_loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "\n",
    "                dqn_optimizer.zero_grad()\n",
    "                dqn_loss.backward()\n",
    "                dqn_optimizer.step()\n",
    "\n",
    "                # Update ICM\n",
    "                icm_optimizer.zero_grad()\n",
    "                inverse_loss, forward_loss = icm(states_tensor, next_states_tensor, actions_tensor)\n",
    "                icm_loss = inverse_loss + forward_loss\n",
    "                icm_loss.backward()\n",
    "                icm_optimizer.step()\n",
    "\n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "\n",
    "        epsilon *= epsilon_decay\n",
    "        print(f\"Episode {episode + 1}, Reward: {episode_reward}, Epsilon: {epsilon}\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(\"Hopper-v2\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    episodes = 1000\n",
    "    batch_size = 64\n",
    "    buffer_size = 100000\n",
    "    gamma = 0.99\n",
    "    epsilon = 1.0\n",
    "    epsilon_decay = 0.995\n",
    "\n",
    "    train_agent(env, episodes, batch_size, buffer_size, gamma, epsilon, epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 1. State Encoder\n",
    "class StateEncoder(nn.Module):\n",
    "    def __init__(self, state_dim, encoding_dim):\n",
    "        super(StateEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(state_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, encoding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        return self.encoder(state)\n",
    "\n",
    "# 2. Inverse Model\n",
    "class InverseModel(nn.Module):\n",
    "    def __init__(self, encoding_dim, action_dim):\n",
    "        super(InverseModel, self).__init__()\n",
    "        self.inverse_model = nn.Sequential(\n",
    "            nn.Linear(encoding_dim * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, action_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, state_encoding, next_state_encoding):\n",
    "        input_tensor = torch.cat([state_encoding, next_state_encoding], dim=1)\n",
    "        return self.inverse_model(input_tensor)\n",
    "\n",
    "# 3. Forward Model\n",
    "class ForwardModel(nn.Module):\n",
    "    def __init__(self, encoding_dim, action_dim, stack_size=4):\n",
    "        super(ForwardModel, self).__init__()\n",
    "        self.stack_size = stack_size\n",
    "        self.forward_model = nn.Sequential(\n",
    "            nn.Linear(encoding_dim * stack_size + action_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, encoding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, state_encoding_stack, action):\n",
    "        input_tensor = torch.cat([state_encoding_stack.view(-1, self.stack_size * state_encoding_stack.shape[-1]), action], dim=1)\n",
    "        return self.forward_model(input_tensor)\n",
    "\n",
    "# 4. Intrinsic Curiosity Module (ICM)\n",
    "class ICM(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, encoding_dim, stack_size=4):\n",
    "        super(ICM, self).__init__()\n",
    "        self.state_encoder = StateEncoder(state_dim, encoding_dim)\n",
    "        self.inverse_model = InverseModel(encoding_dim, action_dim)\n",
    "        self.forward_model = ForwardModel(encoding_dim, action_dim, stack_size)\n",
    "\n",
    "    def forward(self, state, next_state, action):\n",
    "        state_encoding = self.state_encoder(state)\n",
    "        next_state_encoding = self.state_encoder(next_state)\n",
    "\n",
    "        inverse_loss = nn.MSELoss()(self.inverse_model(state_encoding, next_state_encoding), action)\n",
    "\n",
    "        state_encoding_stack = torch.cat([state_encoding.unsqueeze(1)] * self.forward_model.stack_size, dim=1)\n",
    "        forward_loss = nn.MSELoss()(self.forward_model(state_encoding_stack, action), next_state_encoding)\n",
    "\n",
    "        return inverse_loss, forward_loss\n",
    "\n",
    "# Example usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "state_dim = ... # Dimension of the state space\n",
    "action_dim = ... # Dimension of the action space\n",
    "encoding_dim = 64 # Encoding dimension for state representations\n",
    "stack_size = 4 # Number of previous frames to stack\n",
    "\n",
    "# Load your data\n",
    "states, next_states, actions = ... # Load your data\n",
    "\n",
    "dataset = TensorDataset(states, next_states, actions)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "icm = ICM(state_dim, action_dim, encoding_dim, stack_size).to(device)\n",
    "optimizer = optim.Adam(icm.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for states, next_states, actions in dataloader:\n",
    "        states = states.to(device)\n",
    "        next_states = next_states.to(device)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inverse_loss, forward_loss = icm(states, next_states, actions)\n",
    "        loss = inverse_loss + forward_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Inverse Loss: {inverse_loss.item()}, Forward Loss: {forward_loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
