{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM_MoE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_experts):\n",
    "        super(LSTM_MoE, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_experts = num_experts\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        # MoE layer\n",
    "        self.experts = nn.ModuleList([nn.Linear(hidden_dim, output_dim) for _ in range(num_experts)])\n",
    "        self.gating_network = nn.Linear(hidden_dim, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM layer 1\n",
    "        lstm_out, _ = self.lstm1(x)\n",
    "        \n",
    "        # MoE layer\n",
    "        gate_activations = F.softmax(self.gating_network(lstm_out), dim=-1)\n",
    "        expert_outputs = torch.stack([expert(lstm_out) for expert in self.experts], dim=-1)\n",
    "        moe_out = torch.sum(expert_outputs * gate_activations.unsqueeze(2), dim=-1)\n",
    "        \n",
    "        # LSTM layer 2\n",
    "        lstm_out, _ = self.lstm2(moe_out)\n",
    "        return lstm_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists.\n",
      "Downloading dataset...\n",
      "Download completed!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for dataset preparation\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Function to download and extract dataset\n",
    "def download_extract_dataset(url, target_dir):\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    file_name = url.split('/')[-1]\n",
    "    file_path = os.path.join(target_dir, file_name)\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"Downloading dataset...\")\n",
    "        urllib.request.urlretrieve(url, file_path)\n",
    "        print(\"Download completed!\")\n",
    "    else:\n",
    "        print(\"Dataset already exists.\")\n",
    "    return file_path\n",
    "\n",
    "# Download and extract CoNLL-2003 dataset for NER\n",
    "conll_url = \"https://github.com/davidsbatista/NER-datasets/raw/master/CONLL2003/train.txt\"\n",
    "conll_file = download_extract_dataset(conll_url, \"datasets/conll2003\")\n",
    "\n",
    "# Download and extract SQuAD 1.1 dataset for QA\n",
    "squad_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\"\n",
    "squad_file = download_extract_dataset(squad_url, \"datasets/SQuAD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function for NER\n",
    "def train_ner_model(model, train_data, num_epochs, optimizer, criterion):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch in train_data:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, labels = batch\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(\"Epoch {} Loss: {:.4f}\".format(epoch+1, total_loss))\n",
    "\n",
    "# Define training function for QA\n",
    "def train_qa_model(model, train_data, num_epochs, optimizer, criterion):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch in train_data:\n",
    "            optimizer.zero_grad()\n",
    "            context, question, answer_start, answer_end = batch\n",
    "            outputs = model(context, question)\n",
    "            loss = criterion(outputs, answer_start, answer_end)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(\"Epoch {} Loss: {:.4f}\".format(epoch+1, total_loss))\n",
    "\n",
    "# Example usage:\n",
    "# train_ner_model(ner_model, train_data, num_epochs, optimizer, criterion)\n",
    "# train_qa_model(qa_model, train_data, num_epochs, optimizer, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "\n",
    "# Load and preprocess CoNLL-2003 dataset for NER\n",
    "class CoNLLDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            sentence = []\n",
    "            labels = []\n",
    "            for line in lines:\n",
    "                if line == '\\n':\n",
    "                    self.data.append((sentence, labels))\n",
    "                    sentence = []\n",
    "                    labels = []\n",
    "                else:\n",
    "                    word, pos, chunk, label = line.strip().split(' ')\n",
    "                    sentence.append(word)\n",
    "                    labels.append(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Load CoNLL-2003 dataset\n",
    "conll_dataset = CoNLLDataset(conll_file)\n",
    "\n",
    "# Load and preprocess SQuAD 1.1 dataset for QA\n",
    "class SquadDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            squad_data = json.load(f)['data']\n",
    "            self.data = []\n",
    "            for article in squad_data:\n",
    "                for paragraph in article['paragraphs']:\n",
    "                    context = paragraph['context']\n",
    "                    for qa in paragraph['qas']:\n",
    "                        question = qa['question']\n",
    "                        answers = qa['answers']\n",
    "                        self.data.append((context, question, answers))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        context, question, answers = self.data[idx]\n",
    "        answer_start = [answer['answer_start'] for answer in answers]\n",
    "        answer_end = [answer_start[i] + len(answers[i]['text']) for i in range(len(answers))]\n",
    "        return context, question, answer_start, answer_end\n",
    "\n",
    "# Load SQuAD 1.1 dataset\n",
    "squad_dataset = SquadDataset(squad_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "num_classes = 10\n",
    "num_experts = 5\n",
    "\n",
    "# Define model for Named Entity Recognition\n",
    "ner_model = LSTM_MoE(input_dim=embedding_dim, hidden_dim=hidden_dim, output_dim=num_classes, num_experts=num_experts)\n",
    "\n",
    "# Define model for Question Answering\n",
    "qa_model = LSTM_MoE(input_dim=embedding_dim, hidden_dim=hidden_dim, output_dim=num_classes, num_experts=num_experts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "# Define data loaders\n",
    "conll_loader = DataLoader(conll_dataset, batch_size=batch_size, shuffle=True)\n",
    "squad_loader = DataLoader(squad_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define training parameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "optimizer1 = optim.Adam(ner_model.parameters(), lr=learning_rate)\n",
    "optimizer2 = optim.Adam(qa_model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train NER model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_ner_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mner_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconll_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m, in \u001b[0;36mtrain_ner_model\u001b[1;34m(model, train_data, num_epochs, optimizer, criterion)\u001b[0m\n\u001b[0;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      8\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m----> 9\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert labels to tensor\u001b[39;00m\n\u001b[0;32m     10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "\u001b[1;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "# Train NER model\n",
    "train_ner_model(ner_model, conll_loader, num_epochs, optimizer1, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train QA model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_qa_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqa_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquad_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36mtrain_qa_model\u001b[1;34m(model, train_data, num_epochs, optimizer, criterion)\u001b[0m\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     23\u001b[0m context, question, answer_start, answer_end \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m---> 24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, answer_start, answer_end)\n\u001b[0;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train QA model\n",
    "train_qa_model(qa_model, squad_loader, num_epochs, optimizer2, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m precision, recall, f1_score\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Evaluate NER model\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m precision, recall, f1_score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_ner_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mner_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconll_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNER Model Evaluation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m, Recall: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m, F1-score: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(precision, recall, f1_score))\n",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m, in \u001b[0;36mevaluate_ner_model\u001b[1;34m(model, data_loader)\u001b[0m\n\u001b[0;32m      6\u001b[0m predicted_entities \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[0;32m      9\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     10\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Vimarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:140\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    138\u001b[0m elem_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(it))\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "# Define function for evaluating NER model\n",
    "def evaluate_ner_model(model, data_loader):\n",
    "    model.eval()\n",
    "    total_entities = 0\n",
    "    true_entities = 0\n",
    "    predicted_entities = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs, labels = batch\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_entities += labels.size(0)\n",
    "            true_entities += torch.sum(labels == predicted).item()\n",
    "            predicted_entities += torch.sum(predicted).item()\n",
    "    precision = true_entities / predicted_entities\n",
    "    recall = true_entities / total_entities\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Evaluate NER model\n",
    "precision, recall, f1_score = evaluate_ner_model(ner_model, conll_loader)\n",
    "print(\"NER Model Evaluation:\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}\".format(precision, recall, f1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for evaluating QA model\n",
    "def evaluate_qa_model(model, data_loader):\n",
    "    model.eval()\n",
    "    total_examples = 0\n",
    "    exact_matches = 0\n",
    "    f1_scores = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            context, question, answer_start, answer_end = batch\n",
    "            outputs = model(context, question)\n",
    "            # Perform answer prediction logic here\n",
    "            # Calculate EM and F1-score\n",
    "    em_accuracy = exact_matches / total_examples\n",
    "    f1_avg = f1_scores / total_examples\n",
    "    return em_accuracy, f1_avg\n",
    "\n",
    "# Evaluate QA model\n",
    "em_accuracy, f1_avg = evaluate_qa_model(qa_model, squad_loader)\n",
    "print(\"QA Model Evaluation:\")\n",
    "print(\"Exact Match Accuracy: {:.4f}, F1-score: {:.4f}\".format(em_accuracy, f1_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
